# ğŸ“ GuÃ­a Completa: CÃ³mo Funcionan los Agentes en Python

## Â¿QuÃ© es un Agente de IA?

Un **agente de IA** es un programa que puede:
- **Pensar** usando modelos de lenguaje (como GPT-4)
- **Actuar** ejecutando tareas especÃ­ficas
- **Recordar** informaciÃ³n para usarla despuÃ©s
- **Tomar decisiones** basÃ¡ndose en el contexto

Piensa en un agente como un **asistente inteligente** que tiene un trabajo especÃ­fico.

---

## ğŸ—ï¸ Arquitectura de Study Agents

### Sistema Multi-Agente

En lugar de tener un solo agente que haga todo, tenemos **5 agentes especializados** que trabajan juntos:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Study Agents System                     â”‚
â”‚                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚   Content    â”‚  â”‚ Explanation â”‚           â”‚
â”‚  â”‚  Processor   â”‚  â”‚   Agent     â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚     Q&A      â”‚  â”‚     Test     â”‚           â”‚
â”‚  â”‚  Assistant   â”‚  â”‚  Generator  â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚  â”‚   Feedback   â”‚                              â”‚
â”‚  â”‚    Agent     â”‚                              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â”‚                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚      Memory Manager (ChromaDB)        â”‚     â”‚
â”‚  â”‚  - Almacena documentos                â”‚     â”‚
â”‚  â”‚  - Recupera informaciÃ³n relevante     â”‚     â”‚
â”‚  â”‚  - Guarda historial de conversaciÃ³n   â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“š Conceptos Clave

### 1. **RAG (Retrieval-Augmented Generation)**

**Â¿QuÃ© es?**
- TÃ©cnica que combina bÃºsqueda de informaciÃ³n + generaciÃ³n de texto
- En lugar de que el modelo "recuerde" todo, busca informaciÃ³n relevante cuando la necesita

**CÃ³mo funciona:**
```
1. Documentos â†’ Se dividen en "chunks" (pedazos)
2. Chunks â†’ Se convierten en "embeddings" (vectores numÃ©ricos)
3. Embeddings â†’ Se almacenan en una base de datos (ChromaDB)
4. Cuando preguntas algo â†’ Busca chunks similares
5. Chunks encontrados â†’ Se envÃ­an al LLM como contexto
6. LLM â†’ Genera respuesta usando ese contexto
```

**Ejemplo:**
```python
# 1. Procesar documento
documents = ["La IA es...", "Machine Learning es...", ...]

# 2. Buscar informaciÃ³n relevante
query = "Â¿QuÃ© es inteligencia artificial?"
relevant_docs = memory.retrieve_relevant_content(query)

# 3. Generar respuesta con contexto
answer = llm.generate(context=relevant_docs, question=query)
```

---

### 2. **LangChain**

**Â¿QuÃ© es?**
- Framework para construir aplicaciones con LLMs
- Facilita conectar diferentes componentes (modelos, bases de datos, etc.)

**Componentes principales:**
- **LLMs**: Modelos de lenguaje (GPT-4, etc.)
- **Chains**: Secuencias de operaciones
- **Prompts**: Plantillas para instrucciones al modelo
- **Memory**: GestiÃ³n de conversaciones

**Ejemplo:**
```python
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate

# 1. Inicializar modelo
llm = ChatOpenAI(model="gpt-4")

# 2. Crear prompt
prompt = ChatPromptTemplate.from_messages([
    ("system", "Eres un profesor experto"),
    ("user", "Explica: {concept}")
])

# 3. Crear chain (cadena de operaciones)
chain = prompt | llm

# 4. Ejecutar
response = chain.invoke({"concept": "Machine Learning"})
```

---

### 3. **ChromaDB**

**Â¿QuÃ© es?**
- Base de datos vectorial (almacena embeddings)
- Permite bÃºsqueda semÃ¡ntica (buscar por significado, no solo palabras exactas)

**CÃ³mo funciona:**
```python
# 1. Crear colecciÃ³n
collection = client.create_collection("study_content")

# 2. Almacenar documentos
collection.add(
    documents=["Texto 1", "Texto 2", ...],
    ids=["doc1", "doc2", ...]
)

# 3. Buscar documentos similares
results = collection.query(
    query_texts=["Â¿QuÃ© es la IA?"],
    n_results=5
)
```

---

## ğŸ¤– Los 5 Agentes Explicados

### 1. Content Processor Agent

**FunciÃ³n:** Procesa documentos PDF y los almacena

**CÃ³mo funciona:**
```python
class ContentProcessorAgent:
    def process_documents(self, document_paths):
        # 1. Cargar PDFs
        pages = PyPDFLoader(path).load()
        
        # 2. Dividir en chunks
        chunks = text_splitter.split_documents(pages)
        
        # 3. Almacenar en memoria
        memory.store_documents(chunks)
```

**Flujo:**
```
PDF â†’ Cargar â†’ Dividir en chunks â†’ Crear embeddings â†’ Guardar en ChromaDB
```

---

### 2. Explanation Agent

**FunciÃ³n:** Genera explicaciones claras del contenido

**CÃ³mo funciona:**
```python
class ExplanationAgent:
    def generate_explanations(self):
        # 1. Recuperar contenido
        content = memory.retrieve_relevant_content("")
        
        # 2. Crear prompt educativo
        prompt = "Explica esto de manera clara: {content}"
        
        # 3. Generar explicaciÃ³n
        explanation = llm.invoke(prompt)
        
        return explanation
```

**Flujo:**
```
Contenido â†’ Prompt educativo â†’ LLM â†’ ExplicaciÃ³n clara
```

---

### 3. Q&A Assistant Agent

**FunciÃ³n:** Responde preguntas del estudiante

**CÃ³mo funciona:**
```python
class QAAssistantAgent:
    def answer_question(self, question):
        # 1. Buscar contenido relevante
        relevant = memory.retrieve_relevant_content(question)
        
        # 2. Obtener historial
        history = memory.get_conversation_history()
        
        # 3. Generar respuesta con contexto
        answer = llm.invoke({
            "context": relevant,
            "history": history,
            "question": question
        })
        
        # 4. Guardar en historial
        memory.add_to_history(question, answer)
        
        return answer
```

**Flujo:**
```
Pregunta â†’ Buscar contexto â†’ AÃ±adir historial â†’ LLM â†’ Respuesta
```

---

### 4. Test Generator Agent

**FunciÃ³n:** Genera tests personalizados

**CÃ³mo funciona:**
```python
class TestGeneratorAgent:
    def generate_test(self, difficulty, num_questions):
        # 1. Recuperar contenido
        content = memory.retrieve_relevant_content("")
        
        # 2. Crear prompt para generar test
        prompt = f"""
        Genera {num_questions} preguntas de nivel {difficulty}
        basÃ¡ndote en: {content}
        """
        
        # 3. Generar test (formato JSON)
        test = llm.invoke(prompt)
        
        # 4. Almacenar test
        self.generated_tests[test_id] = test
        
        return test
```

**Flujo:**
```
Contenido â†’ Prompt de test â†’ LLM â†’ Test en JSON â†’ Almacenar
```

---

### 5. Feedback Agent

**FunciÃ³n:** Corrige tests y da feedback

**CÃ³mo funciona:**
```python
class FeedbackAgent:
    def grade_test(self, test_id, answers):
        # 1. Obtener test original
        test = test_generator.get_test(test_id)
        
        # 2. Comparar respuestas
        for question in test.questions:
            is_correct = answers[question.id] == question.correct_answer
            
            # 3. Generar feedback
            feedback = llm.invoke({
                "question": question,
                "student_answer": answers[question.id],
                "is_correct": is_correct
            })
        
        # 4. Generar feedback general
        general_feedback = self._generate_general_feedback(score)
        
        return {
            "score": score,
            "feedback": feedback,
            "recommendations": recommendations
        }
```

**Flujo:**
```
Respuestas â†’ Comparar â†’ Generar feedback â†’ Recomendaciones
```

---

## ğŸ”„ Flujo Completo del Sistema

```
1. Usuario sube PDFs
   â†“
2. Content Processor procesa y almacena
   â†“
3. Explanation Agent genera explicaciones
   â†“
4. Usuario hace preguntas
   â†“
5. Q&A Assistant responde
   â†“
6. Usuario solicita test
   â†“
7. Test Generator crea test
   â†“
8. Usuario responde test
   â†“
9. Feedback Agent corrige y da feedback
   â†“
10. Usuario puede repetir desde paso 4
```

---

## ğŸ› ï¸ CÃ³mo Usar el Sistema

### Paso 1: Instalar Dependencias

```bash
cd study_agents
pip install -r requirements.txt
```

### Paso 2: Configurar API Key

```bash
# Crear archivo .env
echo "OPENAI_API_KEY=tu_key_aqui" > .env
```

### Paso 3: Ejecutar la API

```bash
# OpciÃ³n 1: Directamente
python api/main.py

# OpciÃ³n 2: Con uvicorn
uvicorn api.main:app --reload
```

### Paso 4: Abrir Interfaz Web

Abre tu navegador en: `http://localhost:8000`

---

## ğŸ“ Ejemplo de CÃ³digo Completo

```python
from main import StudyAgentsSystem

# 1. Inicializar sistema
system = StudyAgentsSystem()

# 2. Subir documentos
system.upload_documents(["documents/temario.pdf"])

# 3. Generar explicaciones
explanations = system.generate_explanations()

# 4. Hacer pregunta
answer = system.ask_question("Â¿QuÃ© es la IA?")

# 5. Generar test
test = system.generate_test(difficulty="medium", num_questions=5)

# 6. Corregir test
feedback = system.grade_test(
    test_id=test["test_id"],
    answers={"q1": "A", "q2": "True", ...}
)
```

---

## ğŸ¯ Puntos Clave para Entender

1. **Cada agente tiene un trabajo especÃ­fico** - EspecializaciÃ³n
2. **Comparten la misma memoria** - ChromaDB almacena todo
3. **Usan LLMs para generar texto** - GPT-4 para respuestas
4. **RAG para contexto** - Buscan informaciÃ³n relevante antes de responder
5. **Sistema modular** - FÃ¡cil aÃ±adir nuevos agentes

---

## ğŸš€ PrÃ³ximos Pasos

1. **Experimenta** con la interfaz web
2. **Lee el cÃ³digo** de cada agente
3. **Modifica prompts** para personalizar respuestas
4. **AÃ±ade nuevos agentes** si lo necesitas
5. **Mejora la memoria** con mÃ¡s funcionalidades

---

## â“ Preguntas Frecuentes

**P: Â¿Necesito entender todo esto para usarlo?**
R: No, puedes usar la interfaz web sin saber programar.

**P: Â¿CÃ³mo funciona RAG exactamente?**
R: Busca informaciÃ³n relevante en los documentos antes de generar la respuesta.

**P: Â¿Puedo usar otros modelos ademÃ¡s de GPT-4?**
R: SÃ­, LangChain soporta muchos modelos (Claude, Llama, etc.)

**P: Â¿CÃ³mo mejoro las respuestas?**
R: Ajusta los prompts en cada agente para ser mÃ¡s especÃ­fico.

---

Â¡Espero que esta guÃ­a te ayude a entender cÃ³mo funcionan los agentes! ğŸ“

