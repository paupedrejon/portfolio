"""
Study Agents - Sistema Multi-Agente para Autoaprendizaje
Sistema principal que coordina todos los agentes
"""

import os
from typing import Optional
from dotenv import load_dotenv
# Parche para eliminar 'proxies' en openai.Client que algunas libs antiguas env√≠an
import openai_proxy_patch  # noqa: F401
from agents.content_processor import ContentProcessorAgent
from agents.explanation_agent import ExplanationAgent
from agents.qa_assistant import QAAssistantAgent
from agents.test_generator import TestGeneratorAgent
from agents.feedback_agent import FeedbackAgent
from memory.memory_manager import MemoryManager

# Cargar variables de entorno desde el archivo .env
# Buscar en el directorio actual y en el directorio del script
import os
env_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), '.env')
load_dotenv(env_path)  # Cargar desde la ubicaci√≥n espec√≠fica
load_dotenv()  # Tambi√©n intentar desde el directorio actual

class StudyAgentsSystem:
    """
    Sistema principal que coordina todos los agentes
    """
    
    def __init__(self, api_key: Optional[str] = None):
        """
        Inicializa el sistema y todos los agentes
        
        Args:
            api_key: API key de OpenAI del usuario (opcional)
        """
        # Usar API key proporcionada o de entorno
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        
        # Inicializar memoria con API key
        self.memory = MemoryManager(api_key=self.api_key)
        
        # Inicializar todos los agentes con la misma API key
        self.content_processor = ContentProcessorAgent(memory=self.memory)
        self.explanation_agent = ExplanationAgent(memory=self.memory, api_key=self.api_key)
        self.qa_assistant = QAAssistantAgent(memory=self.memory, api_key=self.api_key)
        self.test_generator = TestGeneratorAgent(memory=self.memory, api_key=self.api_key)
        self.feedback_agent = FeedbackAgent(memory=self.memory, api_key=self.api_key)
        
        print("‚úÖ Sistema Study Agents inicializado correctamente")
        print(f"üìö Memoria: {self.memory.get_memory_type()}")
        if self.api_key:
            print("üîë API Key configurada")
    
    def upload_documents(self, document_paths: list[str]) -> dict:
        """
        Procesa documentos subidos por el usuario
        
        Args:
            document_paths: Lista de rutas a los documentos
            
        Returns:
            Informaci√≥n del procesamiento
        """
        print("\nüìÑ Procesando documentos...")
        
        # Limpiar documentos anteriores antes de procesar nuevos
        # Esto asegura que solo se use el contenido del PDF m√°s reciente
        print("üóëÔ∏è Limpiando documentos anteriores...")
        self.memory.clear_all_documents()
        print("‚úÖ Documentos anteriores eliminados")
        
        processed_content = self.content_processor.process_documents(document_paths)
        print("‚úÖ Documentos procesados y almacenados en memoria")
        return processed_content
    
    def generate_explanations(self) -> dict:
        """
        Genera explicaciones claras del contenido procesado
        
        Returns:
            Explicaciones generadas
        """
        print("\nüìñ Generando explicaciones...")
        explanations = self.explanation_agent.generate_explanations()
        print("‚úÖ Explicaciones generadas")
        return explanations
    
    def generate_notes(self, topics: Optional[list[str]] = None, model: Optional[str] = "gpt-4-turbo") -> str:
        """
        Genera apuntes completos en formato Markdown
        
        Args:
            topics: Lista de temas espec√≠ficos (opcional)
            model: Modelo de OpenAI a usar (opcional, por defecto gpt-4-turbo)
            
        Returns:
            Apuntes en formato Markdown
        """
        print(f"\nüìù Generando apuntes con modelo {model}...")
        notes = self.explanation_agent.generate_notes(topics=topics, model=model)
        print("‚úÖ Apuntes generados")
        return notes
    
    def ask_question(self, question: str, user_id: str = "default", model: Optional[str] = "gpt-4-turbo") -> tuple[str, dict]:
        """
        Responde una pregunta del estudiante
        
        Args:
            question: Pregunta del estudiante
            user_id: ID del usuario (para historial)
            model: Modelo de OpenAI a usar (opcional, por defecto gpt-4-turbo)
            
        Returns:
            Tupla con (respuesta contextualizada, informaci√≥n de tokens)
        """
        print(f"\n‚ùì Pregunta: {question} (modelo: {model})")
        answer, usage_info = self.qa_assistant.answer_question(question, user_id, model=model)
        print(f"üí° Respuesta generada")
        return answer, usage_info
    
    def generate_test(self, difficulty: str = "medium", num_questions: int = 10, topics: Optional[list[str]] = None, constraints: Optional[str] = None, model: Optional[str] = "gpt-4-turbo") -> tuple[dict, dict]:
        """
        Genera un test personalizado
        
        Args:
            difficulty: Nivel de dificultad (easy, medium, hard)
            num_questions: N√∫mero de preguntas
            topics: Temas espec√≠ficos (opcional)
            constraints: Restricciones o condiciones espec√≠ficas para las preguntas (opcional)
            model: Modelo de OpenAI a usar (opcional, por defecto gpt-4-turbo)
            
        Returns:
            Tupla con (test generado, informaci√≥n de tokens)
        """
        print(f"\nüìù Generando test ({difficulty}, {num_questions} preguntas) con modelo {model}...")
        test = self.test_generator.generate_test(difficulty, num_questions, topics, constraints=constraints, model=model)
        print("‚úÖ Test generado")
        
        # Extraer informaci√≥n de tokens del test
        usage_info = test.get("usage_info", {"inputTokens": 0, "outputTokens": 0})
        # Remover usage_info del test antes de devolverlo
        test_clean = {k: v for k, v in test.items() if k != "usage_info"}
        
        return test_clean, usage_info
    
    def grade_test(self, test_id: str, answers: dict) -> dict:
        """
        Corrige un test y proporciona feedback
        
        Args:
            test_id: ID del test
            answers: Diccionario con las respuestas del estudiante
            
        Returns:
            Feedback detallado
        """
        print(f"\n‚úèÔ∏è Corrigiendo test {test_id}...")
        
        # Obtener el test primero
        test = self.test_generator.get_test(test_id)
        if "error" in test:
            return {"error": test["error"]}
        
        feedback = self.feedback_agent.grade_test(test_id, answers, test_data=test)
        print("‚úÖ Feedback generado")
        return feedback


def main():
    """Funci√≥n principal para ejecutar el sistema"""
    print("=" * 70)
    print("üéì STUDY AGENTS - Sistema Multi-Agente para Autoaprendizaje")
    print("=" * 70)
    
    # Inicializar sistema
    system = StudyAgentsSystem()
    
    # Verificar API key
    if not system.api_key:
        print("\n‚ö†Ô∏è  ADVERTENCIA: No se encontr√≥ API key de OpenAI")
        print("   El sistema se ha inicializado pero requerir√° API key para usar las funciones.")
        print("\n   Para configurar:")
        print("   1. Crea un archivo .env en esta carpeta con:")
        print("      OPENAI_API_KEY=sk-tu-api-key-aqui")
        print("   2. O configura la variable de entorno:")
        print("      $env:OPENAI_API_KEY='sk-tu-api-key-aqui'")
        print("   3. O p√°sala al inicializar: system = StudyAgentsSystem(api_key='sk-...')")
    else:
        print("\n‚úÖ API key configurada correctamente")
    
    print("\n‚úÖ Sistema listo para usar")
    print("üìñ Consulta la documentaci√≥n para m√°s detalles")


if __name__ == "__main__":
    main()
