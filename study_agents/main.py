"""
Study Agents - Sistema Multi-Agente para Autoaprendizaje
Sistema principal que coordina todos los agentes
"""

import os
from typing import Optional
from dotenv import load_dotenv

# APLICAR PARCHE DE PROXIES ANTES DE CUALQUIER IMPORTACI√ìN DE AGENTES
import openai_proxy_patch  # noqa: F401
# Forzar aplicaci√≥n del parche de LangChain tambi√©n
try:
    openai_proxy_patch.patch_langchain_openai()
except:
    pass  # Se aplicar√° cuando se importe langchain_openai

from agents.content_processor import ContentProcessorAgent
from agents.explanation_agent import ExplanationAgent
from agents.qa_assistant import QAAssistantAgent
from agents.test_generator import TestGeneratorAgent
from agents.feedback_agent import FeedbackAgent
from agents.exercise_generator import ExerciseGeneratorAgent
from agents.exercise_corrector import ExerciseCorrectorAgent
from agents.correction_agent import CorrectionAgent
from memory.memory_manager import MemoryManager

# Cargar variables de entorno desde el archivo .env
# Buscar en el directorio actual y en el directorio del script
import os
env_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), '.env')
load_dotenv(env_path)  # Cargar desde la ubicaci√≥n espec√≠fica
load_dotenv()  # Tambi√©n intentar desde el directorio actual

class StudyAgentsSystem:
    """
    Sistema principal que coordina todos los agentes
    """
    
    def __init__(self, api_key: Optional[str] = None, mode: str = "auto"):
        """
        Inicializa el sistema y todos los agentes
        
        Args:
            api_key: API key de OpenAI del usuario (opcional)
            mode: Modo de selecci√≥n de modelo ("auto" = optimizar costes, "manual" = usar modelo especificado)
        """
        # Usar API key proporcionada o de entorno
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        self.mode = mode
        
        # Inicializar memoria con API key
        self.memory = MemoryManager(api_key=self.api_key)
        
        # Inicializar todos los agentes con la misma API key y modo autom√°tico
        self.content_processor = ContentProcessorAgent(memory=self.memory)
        self.explanation_agent = ExplanationAgent(memory=self.memory, api_key=self.api_key, mode=mode)
        self.qa_assistant = QAAssistantAgent(memory=self.memory, api_key=self.api_key, mode=mode)
        self.test_generator = TestGeneratorAgent(memory=self.memory, api_key=self.api_key, mode=mode)
        self.feedback_agent = FeedbackAgent(memory=self.memory, api_key=self.api_key, mode=mode)
        self.exercise_generator = ExerciseGeneratorAgent(memory=self.memory, api_key=self.api_key, mode=mode)
        self.exercise_corrector = ExerciseCorrectorAgent(memory=self.memory, api_key=self.api_key, mode=mode)
        self.correction_agent = CorrectionAgent(memory=self.memory, api_key=self.api_key, mode=mode)
        
        print("‚úÖ Sistema Study Agents inicializado correctamente")
        print(f"üìö Memoria: {self.memory.get_memory_type()}")
        print(f"üîß Modo: {mode} (optimizaci√≥n autom√°tica de costes activada)")
        if self.api_key:
            print("üîë API Key configurada")
        else:
            print("üí° Sin API key - intentando usar Ollama (gratis) si est√° disponible")
    
    def upload_documents(self, document_paths: list[str]) -> dict:
        """
        Procesa documentos subidos por el usuario
        
        Args:
            document_paths: Lista de rutas a los documentos
            
        Returns:
            Informaci√≥n del procesamiento
        """
        print("\nüìÑ Procesando documentos...")
        
        # Limpiar documentos anteriores antes de procesar nuevos
        # Esto asegura que solo se use el contenido del PDF m√°s reciente
        print("üóëÔ∏è Limpiando documentos anteriores...")
        self.memory.clear_all_documents()
        print("‚úÖ Documentos anteriores eliminados")
        
        processed_content = self.content_processor.process_documents(document_paths)
        print("‚úÖ Documentos procesados y almacenados en memoria")
        return processed_content
    
    def generate_explanations(self) -> dict:
        """
        Genera explicaciones claras del contenido procesado
        
        Returns:
            Explicaciones generadas
        """
        print("\nüìñ Generando explicaciones...")
        explanations = self.explanation_agent.generate_explanations()
        print("‚úÖ Explicaciones generadas")
        return explanations
    
    def generate_notes(self, topics: Optional[list[str]] = None, model: Optional[str] = None, user_id: Optional[str] = None, conversation_history: Optional[list[dict]] = None, topic: Optional[str] = None, user_level: Optional[int] = None, chat_id: Optional[str] = None) -> str:
        """
        Genera resumen completo de la conversaci√≥n en formato Markdown
        
        Args:
            topics: Lista de temas espec√≠ficos (opcional)
            model: Modelo preferido (opcional, si no se especifica usa modo autom√°tico)
            user_id: ID del usuario para obtener su nivel (opcional)
            conversation_history: Historial de conversaci√≥n para generar resumen actualizado (opcional)
            
        Returns:
            Resumen en formato Markdown
        """
        # Usar el nivel pasado como par√°metro, o intentar obtenerlo si no est√° disponible
        if user_level is None:
            # Priorizar topic sobre topics
            main_topic = topic if topic else (topics[0] if topics and len(topics) > 0 else None)
            
            if user_id and main_topic:
                try:
                    from progress_tracker import ProgressTracker
                    tracker = ProgressTracker()
                    topic_data = tracker.get_topic_level(user_id, main_topic)
                    user_level = topic_data.get("level", 0)
                    print(f"üìä Nivel del usuario en '{main_topic}': {user_level}/10")
                except Exception as e:
                    print(f"‚ö†Ô∏è No se pudo obtener el nivel del usuario: {e}")
                    user_level = 0
        
        model_str = model if model else "autom√°tico (optimizando costes)"
        print(f"\nüìù Generando resumen con modelo {model_str}...")
        if user_level is not None:
            print(f"üìä Usando nivel del usuario: {user_level}/10")
        
        # Si no hay historial y hay chat_id, usar el t√≠tulo del chat como contexto
        if not conversation_history and chat_id and user_id:
            try:
                from chat_storage import load_chat
                chat_data = load_chat(user_id, chat_id)
                if chat_data and chat_data.get("title"):
                    # Usar el t√≠tulo como contexto inicial
                    if not topic:
                        topic = chat_data.get("title")
                    print(f"üìã Usando t√≠tulo del chat como tema: {chat_data.get('title')}")
            except Exception as e:
                print(f"‚ö†Ô∏è No se pudo obtener el t√≠tulo del chat: {e}")
        
        # Generar apuntes iniciales
        notes, usage_info_notes = self.explanation_agent.generate_notes(topics=topics, model=model, user_level=user_level, conversation_history=conversation_history, topic=topic, chat_id=chat_id, user_id=user_id)
        print(f"üí° Apuntes generados ({len(notes)} caracteres)")
        
        # Revisar y corregir los apuntes usando el agente corrector
        try:
            # Obtener apuntes anteriores si hay historial de conversaci√≥n
            previous_notes = None
            if conversation_history:
                # Buscar apuntes anteriores en el historial
                for msg in reversed(conversation_history):
                    if msg.get('role') == 'assistant' and ('# ' in msg.get('content', '') or '## ' in msg.get('content', '')):
                        # Parece ser apuntes
                        previous_notes = msg.get('content', '')
                        if len(previous_notes) > 500:  # Solo si es suficientemente largo
                            break
            
            # Revisar y corregir
            print("üîç Revisando apuntes con agente corrector (verificando variaci√≥n y calidad)...")
            corrected_notes, needs_correction, correction_analysis, nivel_ajustado = self.correction_agent.review_and_correct(
                response=notes,
                question=f"Generar apuntes sobre {topic or (topics[0] if topics and len(topics) > 0 else 'el tema')}",
                conversation_history=conversation_history,
                topic=topic,
                context=None,  # Los apuntes ya tienen el contexto integrado
                model=model,
                user_level=user_level,
                is_notes=True,
                previous_notes=previous_notes,
                user_id=user_id,
                chat_id=None  # No hay chat_id para apuntes, pero podemos usar user_id y topic
            )
            
            # Aplicar ajuste de nivel si el agente lo recomienda
            if nivel_ajustado is not None and user_id and topic:
                try:
                    from progress_tracker import ProgressTracker
                    tracker = ProgressTracker()
                    # Buscar el chat_id asociado al tema
                    user_progress = tracker.get_user_progress(user_id)
                    if "chats" in user_progress:
                        for cid, chat_data in user_progress["chats"].items():
                            if chat_data.get("topic") == topic:
                                tracker.set_chat_level(user_id, cid, nivel_ajustado, topic)
                                print(f"üìä Nivel ajustado autom√°ticamente: {user_level or 0} ‚Üí {nivel_ajustado}/10")
                                break
                except Exception as e:
                    print(f"‚ö†Ô∏è Error al ajustar nivel: {e}")
            
            if needs_correction:
                print(f"‚úÖ Apuntes corregidos (problemas detectados: {len(correction_analysis.get('problemas', []))})")
                if correction_analysis.get('problemas'):
                    print(f"   Problemas: {', '.join(correction_analysis['problemas'][:3])}")
                
                # Si se fuerza regeneraci√≥n porque son muy similares, regenerar completamente
                if correction_analysis.get('force_regeneration'):
                    print("üîÑ Regenerando apuntes completamente diferentes...")
                    # Regenerar con instrucciones expl√≠citas de variaci√≥n
                    notes = self.explanation_agent.generate_notes(
                        topics=topics, 
                        model=model, 
                        user_level=user_level, 
                        conversation_history=conversation_history, 
                        topic=topic
                    )
                    # Usar nivel ajustado si est√° disponible
                    nivel_a_usar = nivel_ajustado if nivel_ajustado is not None else user_level
                    # Revisar de nuevo
                    corrected_notes2, needs_correction2, _, nivel_ajustado2 = self.correction_agent.review_and_correct(
                        response=notes,
                        question=f"Generar apuntes sobre {topic or (topics[0] if topics and len(topics) > 0 else 'el tema')}",
                        conversation_history=conversation_history,
                        topic=topic,
                        context=None,
                        model=model,
                        user_level=nivel_a_usar,
                        is_notes=True,
                        previous_notes=previous_notes,
                        user_id=user_id,
                        chat_id=None
                    )
                    # Aplicar segundo ajuste de nivel si es necesario
                    if nivel_ajustado2 is not None and user_id and topic:
                        try:
                            from progress_tracker import ProgressTracker
                            tracker = ProgressTracker()
                            user_progress = tracker.get_user_progress(user_id)
                            if "chats" in user_progress:
                                for cid, chat_data in user_progress["chats"].items():
                                    if chat_data.get("topic") == topic:
                                        tracker.set_chat_level(user_id, cid, nivel_ajustado2, topic)
                                        print(f"üìä Nivel ajustado autom√°ticamente (segunda revisi√≥n): {nivel_a_usar or 0} ‚Üí {nivel_ajustado2}/10")
                                        break
                        except Exception as e:
                            print(f"‚ö†Ô∏è Error al ajustar nivel: {e}")
                    return corrected_notes2 if needs_correction2 else notes
                
                return corrected_notes
            else:
                print("‚úÖ Apuntes aprobados (no necesita correcci√≥n)")
                return notes
                
        except Exception as e:
            print(f"‚ö†Ô∏è Error en correcci√≥n de apuntes, usando apuntes originales: {e}")
            return notes
    
    def _detect_negative_feedback(self, question: str) -> bool:
        """
        Detecta si el usuario est√° dando feedback negativo o pidiendo mejor calidad
        
        Args:
            question: Pregunta del usuario
            
        Returns:
            True si se detecta feedback negativo o necesidad de alta calidad
        """
        question_lower = question.lower()
        
        # Palabras clave que indican feedback negativo
        negative_keywords = [
            "est√° mal", "esta mal", "est√° incorrecto", "esta incorrecto",
            "no es correcto", "no es as√≠", "no es eso", "no es lo que ped√≠",
            "hazlo mejor", "hazlo de nuevo", "vuelve a hacerlo", "rehazlo",
            "mejor respuesta", "respuesta mejor", "m√°s detallado", "m√°s completo",
            "no entiendo", "no me sirve", "no me ayuda", "no es √∫til",
            "est√°s equivocado", "te equivocas", "es incorrecto", "es falso",
            "corrige", "corrigelo", "corr√≠gelo", "arregla", "arreglalo",
            "mejor explicaci√≥n", "explica mejor", "m√°s claro", "m√°s preciso",
            "no es lo que busco", "no es lo que necesito", "no responde",
            "falta informaci√≥n", "incompleto", "muy simple", "muy b√°sico"
        ]
        
        # Detectar si contiene alguna palabra clave negativa
        for keyword in negative_keywords:
            if keyword in question_lower:
                print(f"‚ö†Ô∏è Feedback negativo detectado: '{keyword}' ‚Üí Usando modelo premium")
                return True
        
        # Detectar si pregunta expl√≠citamente por mejor calidad
        quality_keywords = [
            "mejor calidad", "m√°xima calidad", "mejor modelo", "modelo mejor",
            "usa gpt-5", "usa gpt5", "gpt-5", "gpt5", "gpt 5"
        ]
        
        for keyword in quality_keywords:
            if keyword in question_lower:
                print(f"‚úÖ Solicitud de alta calidad detectada: '{keyword}' ‚Üí Usando modelo premium")
                return True
        
        return False
    
    def ask_question(self, question: str, user_id: str = "default", model: Optional[str] = None, chat_id: Optional[str] = None, topic: Optional[str] = None, initial_form_data: Optional[dict] = None) -> tuple[str, dict]:
        """
        Responde una pregunta del estudiante
        
        Args:
            question: Pregunta del estudiante
            user_id: ID del usuario (para historial)
            model: Modelo preferido (opcional, si no se especifica usa modo autom√°tico)
            chat_id: ID de la conversaci√≥n (para obtener el nivel)
            topic: Tema del chat (para contextualizar las respuestas)
            
        Returns:
            Tupla con (respuesta contextualizada, informaci√≥n de tokens)
        """
        # Detectar si el usuario est√° dando feedback negativo o pidiendo mejor calidad
        needs_premium = self._detect_negative_feedback(question)
        
        # Si se detecta feedback negativo y no hay modelo espec√≠fico, usar GPT-5 autom√°ticamente
        if needs_premium and not model:
            print(f"üöÄ Usando GPT-5 autom√°ticamente debido a feedback negativo o solicitud de alta calidad")
        
        model_str = model if model else ("GPT-5 (autom√°tico por feedback negativo)" if needs_premium else "autom√°tico (optimizando costes)")
        print(f"\n‚ùì Pregunta: {question} (modelo: {model_str}, tema: {topic or 'General'})")
        
        # Generar respuesta inicial (pasar force_premium si se detect√≥ feedback negativo)
        answer, usage_info = self.qa_assistant.answer_question(
            question, 
            user_id, 
            model=model, 
            chat_id=chat_id, 
            topic=topic,
            force_premium=needs_premium  # Forzar premium si se detect√≥ feedback negativo
        )
        print(f"üí° Respuesta generada ({len(answer)} caracteres)")
        
        # NO usar corrector para flashcards, tests o ejercicios
        # Las flashcards usan user_id="flashcards" y chat_id="flashcards"
        # Los tests y ejercicios tienen su propia l√≥gica de generaci√≥n
        skip_corrector = (
            user_id == "flashcards" or 
            chat_id == "flashcards" or
            "flashcard" in question.lower() or
            "test" in question.lower() or
            "ejercicio" in question.lower() or
            question.strip().startswith("Genera") and ("conceptos" in question.lower() or "palabras" in question.lower())
        )
        
        if skip_corrector:
            print("‚è≠Ô∏è Saltando corrector (flashcards/tests/ejercicios)")
            return answer, usage_info
        
        # Revisar y corregir la respuesta usando el agente corrector
        try:
            # Obtener historial de conversaci√≥n para el corrector (solo del chat actual)
            conversation_history = self.memory.get_conversation_history(user_id, chat_id)
            
            # Obtener contexto relevante (solo del chat actual)
            relevant_content = self.memory.retrieve_relevant_content(question, n_results=3, chat_id=chat_id, user_id=user_id)
            context = "\n\n".join(relevant_content) if relevant_content else None
            
            # Si no hay contexto y no hay historial, usar el t√≠tulo del chat como contexto
            if not context and not conversation_history and chat_id:
                try:
                    from chat_storage import load_chat
                    chat_data = load_chat(user_id, chat_id)
                    if chat_data and chat_data.get("title"):
                        context = f"Tema del chat: {chat_data.get('title')}"
                        print(f"üìã Usando t√≠tulo del chat como contexto: {chat_data.get('title')}")
                except Exception as e:
                    print(f"‚ö†Ô∏è No se pudo obtener el t√≠tulo del chat: {e}")
            
            # Obtener nivel del usuario si hay chat_id
            user_level = None
            if user_id and chat_id:
                try:
                    from progress_tracker import ProgressTracker
                    tracker = ProgressTracker()
                    chat_data = tracker.get_chat_level(user_id, chat_id)
                    user_level = chat_data.get("level", 0)
                except Exception as e:
                    print(f"‚ö†Ô∏è No se pudo obtener el nivel del usuario: {e}")
            
            # Revisar y corregir
            print("üîç Revisando respuesta con agente corrector (modo cr√≠tico)...")
            corrected_answer, needs_correction, correction_analysis, nivel_ajustado = self.correction_agent.review_and_correct(
                response=answer,
                question=question,
                conversation_history=conversation_history,
                topic=topic,
                context=context,
                model=model,
                user_level=user_level,
                user_id=user_id,
                chat_id=chat_id
            )
            
            # Aplicar ajuste de nivel si el agente lo recomienda
            if nivel_ajustado is not None and user_id and chat_id:
                try:
                    from progress_tracker import ProgressTracker
                    tracker = ProgressTracker()
                    tracker.set_chat_level(user_id, chat_id, nivel_ajustado, topic)
                    print(f"üìä Nivel ajustado autom√°ticamente: {user_level or 0} ‚Üí {nivel_ajustado}/10")
                except Exception as e:
                    print(f"‚ö†Ô∏è Error al ajustar nivel: {e}")
            
            if needs_correction:
                print(f"‚úÖ Respuesta corregida (problemas detectados: {len(correction_analysis.get('problemas', []))})")
                if correction_analysis.get('problemas'):
                    print(f"   Problemas: {', '.join(correction_analysis['problemas'][:3])}")
                return corrected_answer, usage_info
            else:
                print("‚úÖ Respuesta aprobada (no necesita correcci√≥n)")
                return answer, usage_info
                
        except Exception as e:
            print(f"‚ö†Ô∏è Error en correcci√≥n, usando respuesta original: {e}")
            return answer, usage_info
    
    def generate_test(self, difficulty: str = "medium", num_questions: int = 10, topics: Optional[list[str]] = None, constraints: Optional[str] = None, model: Optional[str] = None, conversation_history: Optional[list[dict]] = None, user_id: Optional[str] = None, chat_id: Optional[str] = None, user_level: Optional[int] = None) -> tuple[dict, dict]:
        """
        Genera un test personalizado
        
        Args:
            difficulty: Nivel de dificultad (easy, medium, hard)
            num_questions: N√∫mero de preguntas
            topics: Temas espec√≠ficos (opcional)
            constraints: Restricciones o condiciones espec√≠ficas para las preguntas (opcional)
            model: Modelo preferido (opcional, si no se especifica usa modo autom√°tico)
            conversation_history: Historial de conversaci√≥n del chat (opcional)
            user_id: ID del usuario para obtener su nivel (opcional)
            chat_id: ID de la conversaci√≥n para obtener el nivel (opcional)
            user_level: Nivel del usuario (0-10) si ya se obtuvo (opcional)
            
        Returns:
            Tupla con (test generado, informaci√≥n de tokens)
        """
        # Obtener nivel del usuario desde la conversaci√≥n si hay chat_id y no se proporcion√≥ user_level
        if user_level is None and user_id and chat_id:
            try:
                from progress_tracker import ProgressTracker
                tracker = ProgressTracker()
                chat_data = tracker.get_chat_level(user_id, chat_id)
                user_level = chat_data.get("level", 0)
                print(f"üìä Nivel del usuario en conversaci√≥n '{chat_id}': {user_level}/10")
            except Exception as e:
                print(f"‚ö†Ô∏è No se pudo obtener el nivel del usuario: {e}")
                user_level = 0
        
        model_str = model if model else "autom√°tico (optimizando costes)"
        print(f"\nüìù Generando test ({difficulty}, {num_questions} preguntas, nivel usuario: {user_level if user_level is not None else 'N/A'}/10) con modelo {model_str}...")
        test = self.test_generator.generate_test(difficulty, num_questions, topics, constraints=constraints, model=model, conversation_history=conversation_history, user_level=user_level)
        print("‚úÖ Test generado")
        
        # Extraer informaci√≥n de tokens del test
        usage_info = test.get("usage_info", {"inputTokens": 0, "outputTokens": 0})
        # Remover usage_info del test antes de devolverlo
        test_clean = {k: v for k, v in test.items() if k != "usage_info"}
        
        return test_clean, usage_info
    
    def grade_test(self, test_id: str, answers: dict) -> dict:
        """
        Corrige un test y proporciona feedback
        
        Args:
            test_id: ID del test
            answers: Diccionario con las respuestas del estudiante
            
        Returns:
            Feedback detallado
        """
        print(f"\n‚úèÔ∏è Corrigiendo test {test_id}...")
        
        # Obtener el test primero
        test = self.test_generator.get_test(test_id)
        if "error" in test:
            return {"error": test["error"]}
        
        feedback = self.feedback_agent.grade_test(test_id, answers, test_data=test)
        print("‚úÖ Feedback generado")
        return feedback
    
    def generate_exercise(
        self,
        difficulty: str = "medium",
        topics: Optional[list[str]] = None,
        exercise_type: Optional[str] = None,
        constraints: Optional[str] = None,
        model: Optional[str] = None,
        conversation_history: Optional[list[dict]] = None,
        user_id: Optional[str] = None,
        user_level: Optional[int] = None,
        chat_id: Optional[str] = None
    ) -> tuple[dict, dict]:
        """
        Genera un ejercicio complejo
        
        Args:
            difficulty: Nivel de dificultad (easy, medium, hard)
            topics: Temas espec√≠ficos (opcional)
            exercise_type: Tipo de ejercicio (opcional)
            constraints: Restricciones o condiciones espec√≠ficas para el ejercicio (opcional)
            model: Modelo preferido (opcional, si no se especifica usa modo autom√°tico)
            conversation_history: Historial de conversaci√≥n reciente (opcional)
            user_id: ID del usuario para obtener su nivel (opcional)
            user_level: Nivel del usuario (opcional, si no se proporciona se obtiene autom√°ticamente)
            
        Returns:
            Tupla con (ejercicio generado, informaci√≥n de tokens)
        """
        # Obtener nivel del usuario si hay user_id y topics
        if user_level is None and user_id and topics and len(topics) > 0:
            try:
                from progress_tracker import ProgressTracker
                tracker = ProgressTracker()
                main_topic = topics[0] if isinstance(topics, list) else str(topics)
                topic_data = tracker.get_topic_level(user_id, main_topic)
                user_level = topic_data.get("level", 0)
                print(f"üìä Nivel del usuario en '{main_topic}': {user_level}/10")
            except Exception as e:
                print(f"‚ö†Ô∏è No se pudo obtener el nivel del usuario: {e}")
        
        model_str = model if model else "autom√°tico (optimizando costes)"
        print(f"\nüìù Generando ejercicio ({difficulty}) con modelo {model_str}...")
        
        # Intentar generar el ejercicio hasta 3 veces si hay errores
        max_attempts = 3
        last_error = None
        
        for attempt in range(max_attempts):
            try:
                result = self.exercise_generator.generate_exercise(
                    difficulty=difficulty,
                    topics=topics,
                    exercise_type=exercise_type,
                    constraints=constraints,
                    model=model,
                    conversation_history=conversation_history,
                    user_level=user_level,
                    chat_id=chat_id,
                    user_id=user_id
                )
                
                # El agente devuelve {"exercise": exercise_data, "exercise_id": ..., "usage_info": ...}
                # Extraer el ejercicio y la informaci√≥n de tokens
                if "error" in result:
                    last_error = result["error"]
                    if attempt < max_attempts - 1:
                        print(f"‚ö†Ô∏è Intento {attempt + 1} fall√≥: {last_error}. Reintentando...")
                        continue
                    else:
                        # √öltimo intento fall√≥, intentar generar un ejercicio b√°sico
                        print(f"‚ö†Ô∏è Todos los intentos fallaron. Generando ejercicio b√°sico de respaldo...")
                        exercise_data = {
                            "exercise_id": result.get("exercise_id", "backup_exercise"),
                            "statement": f"Responde la siguiente pregunta sobre {', '.join(topics) if topics else 'el tema'}:",
                            "expected_answer": "Respuesta esperada",
                            "hints": ["Revisa el contenido estudiado", "Piensa paso a paso"],
                            "points": 10,
                            "difficulty": difficulty,
                            "topics": topics or [],
                            "solution_steps": ["Paso 1: Analiza la pregunta", "Paso 2: Identifica los conceptos clave", "Paso 3: Formula tu respuesta"]
                        }
                        usage_info = result.get("usage_info", {"inputTokens": 0, "outputTokens": 0})
                        print("‚úÖ Ejercicio de respaldo generado")
                        return exercise_data, usage_info
                
                exercise_data = result.get("exercise", {})
                usage_info = result.get("usage_info", {"inputTokens": 0, "outputTokens": 0})
                
                # Asegurar que el ejercicio tenga todos los campos necesarios
                if not exercise_data:
                    if attempt < max_attempts - 1:
                        print(f"‚ö†Ô∏è Intento {attempt + 1}: ejercicio vac√≠o. Reintentando...")
                        continue
                    else:
                        raise Exception("No se pudo generar el ejercicio despu√©s de m√∫ltiples intentos")
                
                # Validar campos m√≠nimos
                if "statement" not in exercise_data:
                    exercise_data["statement"] = f"Responde la siguiente pregunta sobre {', '.join(topics) if topics else 'el tema'}:"
                if "expected_answer" not in exercise_data:
                    exercise_data["expected_answer"] = "Respuesta esperada"
                if "points" not in exercise_data:
                    exercise_data["points"] = 10
                if "hints" not in exercise_data:
                    exercise_data["hints"] = []
                if "solution_steps" not in exercise_data:
                    exercise_data["solution_steps"] = []
                
                print("‚úÖ Ejercicio generado exitosamente")
                return exercise_data, usage_info
                
            except Exception as e:
                last_error = str(e)
                if attempt < max_attempts - 1:
                    print(f"‚ö†Ô∏è Intento {attempt + 1} fall√≥ con excepci√≥n: {last_error}. Reintentando...")
                    continue
                else:
                    # √öltimo intento, generar ejercicio b√°sico
                    print(f"‚ö†Ô∏è Todos los intentos fallaron. Generando ejercicio b√°sico de respaldo...")
                    exercise_data = {
                        "exercise_id": f"backup_{attempt}",
                        "statement": f"Responde la siguiente pregunta sobre {', '.join(topics) if topics else 'el tema'}:",
                        "expected_answer": "Respuesta esperada",
                        "hints": ["Revisa el contenido estudiado", "Piensa paso a paso"],
                        "points": 10,
                        "difficulty": difficulty,
                        "topics": topics or [],
                        "solution_steps": ["Paso 1: Analiza la pregunta", "Paso 2: Identifica los conceptos clave", "Paso 3: Formula tu respuesta"]
                    }
                    usage_info = {"inputTokens": 0, "outputTokens": 0}
                    print("‚úÖ Ejercicio de respaldo generado")
                    return exercise_data, usage_info
        
        # Si llegamos aqu√≠, todos los intentos fallaron
        raise Exception(f"No se pudo generar el ejercicio despu√©s de {max_attempts} intentos: {last_error}")
    
    def correct_exercise(
        self,
        exercise: dict,
        student_answer: str,
        model: Optional[str] = None
    ) -> tuple[dict, dict]:
        """
        Corrige un ejercicio y proporciona feedback
        
        Args:
            exercise: Ejercicio con enunciado y respuesta esperada
            student_answer: Respuesta del estudiante
            model: Modelo preferido (opcional, si no se especifica usa modo autom√°tico)
            
        Returns:
            Tupla con (correcci√≥n con nota y feedback, informaci√≥n de tokens)
        """
        model_str = model if model else "autom√°tico (optimizando costes)"
        print(f"\n‚úèÔ∏è Corrigiendo ejercicio con modelo {model_str}...")
        result = self.exercise_corrector.correct_exercise(
            exercise=exercise,
            student_answer=student_answer,
            model=model
        )
        print("‚úÖ Correcci√≥n completada")
        
        # El agente devuelve {"correction": correction_data, "exercise_id": ..., "points": ..., "usage_info": ...}
        # Extraer la correcci√≥n y la informaci√≥n de tokens
        if "error" in result:
            raise Exception(result["error"])
        
        correction_data = result.get("correction", {})
        usage_info = result.get("usage_info", {"inputTokens": 0, "outputTokens": 0})
        
        # Asegurar que la correcci√≥n tenga todos los campos necesarios
        if not correction_data:
            raise Exception("No se pudo corregir el ejercicio")
        
        return correction_data, usage_info


def main():
    """Funci√≥n principal para ejecutar el sistema"""
    print("=" * 70)
    print("üéì STUDY AGENTS - Sistema Multi-Agente para Autoaprendizaje")
    print("=" * 70)
    
    # Inicializar sistema
    system = StudyAgentsSystem()
    
    # Verificar API key
    if not system.api_key:
        print("\n‚ö†Ô∏è  ADVERTENCIA: No se encontr√≥ API key de OpenAI")
        print("   El sistema se ha inicializado pero requerir√° API key para usar las funciones.")
        print("\n   Para configurar:")
        print("   1. Crea un archivo .env en esta carpeta con:")
        print("      OPENAI_API_KEY=sk-tu-api-key-aqui")
        print("   2. O configura la variable de entorno:")
        print("      $env:OPENAI_API_KEY='sk-tu-api-key-aqui'")
        print("   3. O p√°sala al inicializar: system = StudyAgentsSystem(api_key='sk-...')")
    else:
        print("\n‚úÖ API key configurada correctamente")
    
    print("\n‚úÖ Sistema listo para usar")
    print("üìñ Consulta la documentaci√≥n para m√°s detalles")


if __name__ == "__main__":
    main()
