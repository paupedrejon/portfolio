"""
Explanation Agent - Transforma informaci√≥n en explicaciones claras y resumidas
Genera apuntes estructurados del contenido procesado
"""

from typing import List, Dict, Optional
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from memory.memory_manager import MemoryManager
import os
import tiktoken

class ExplanationAgent:
    """
    Agente especializado en generar explicaciones claras y resumidas
    """
    
    def __init__(self, memory: MemoryManager, api_key: Optional[str] = None):
        """
        Inicializa el agente de explicaciones
        
        Args:
            memory: Gestor de memoria del sistema
            api_key: API key de OpenAI (opcional)
        """
        self.memory = memory
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        self.llm = None  # Se inicializar√° cuando se necesite
        
        if self.api_key:
            try:
                # Usar gpt-4-turbo que tiene 128k tokens de contexto (m√°s reciente y estable)
                # Si no est√° disponible, usar gpt-4o que tambi√©n tiene contexto amplio
                try:
                    self.llm = ChatOpenAI(
                        model="gpt-4-turbo",
                        temperature=0.7,
                        api_key=self.api_key,
                        max_tokens=None
                    )
                except:
                    # Fallback a gpt-4o si gpt-4-turbo no est√° disponible
                    self.llm = ChatOpenAI(
                        model="gpt-4o",
                        temperature=0.7,
                        api_key=self.api_key,
                        max_tokens=None
                    )
                print("ü§ñ Explanation Agent inicializado con API key")
            except Exception as e:
                print(f"‚ö†Ô∏è Warning: No se pudo inicializar el LLM: {e}")
        else:
            print("‚ö†Ô∏è Explanation Agent inicializado sin API key (se requerir√° para usar)")
    
    def generate_explanations(self, max_concepts: int = 20) -> Dict[str, str]:
        """
        Genera explicaciones claras del contenido procesado
        
        Args:
            max_concepts: N√∫mero m√°ximo de conceptos a explicar
            
        Returns:
            Diccionario con explicaciones por concepto o texto completo
        """
        # Verificar API key
        if not self.api_key:
            return {
                "error": "Se requiere configurar una API key de OpenAI para generar explicaciones.",
                "status": "error"
            }
        
        # Inicializar LLM si no est√° inicializado
        if not self.llm:
            try:
                # Usar gpt-4-turbo que tiene 128k tokens de contexto (m√°s reciente y estable)
                # Si no est√° disponible, usar gpt-4o que tambi√©n tiene contexto amplio
                try:
                    self.llm = ChatOpenAI(
                        model="gpt-4-turbo",
                        temperature=0.7,
                        api_key=self.api_key,
                        max_tokens=None
                    )
                except:
                    # Fallback a gpt-4o si gpt-4-turbo no est√° disponible
                    self.llm = ChatOpenAI(
                        model="gpt-4o",
                        temperature=0.7,
                        api_key=self.api_key,
                        max_tokens=None
                    )
            except Exception as e:
                return {
                    "error": f"Error al inicializar el modelo: {str(e)}",
                    "status": "error"
                }
        
        # Recuperar todo el contenido de la memoria
        all_content = self.memory.get_all_documents(limit=100)
        
        if not all_content:
            return {"error": "No hay contenido procesado. Sube documentos primero."}
        
        # Combinar contenido en chunks m√°s grandes
        combined_content = "\n\n---\n\n".join(all_content[:max_concepts * 2])
        
        # Generar explicaciones estructuradas
        prompt_template = ChatPromptTemplate.from_messages([
            ("system", """Eres un profesor experto que explica conceptos de manera clara y sencilla.
            Tu tarea es transformar informaci√≥n compleja en explicaciones f√°ciles de entender.
            Mant√©n un tono educativo y amigable.
            Organiza la informaci√≥n de manera estructurada y l√≥gica."""),
            ("user", """Transforma el siguiente contenido educativo en explicaciones claras y estructuradas.

CONTENIDO:
{content}

Genera un documento de apuntes que incluya:
1. **Resumen Ejecutivo**: Un resumen breve de los conceptos principales
2. **Conceptos Clave**: Explicaci√≥n clara de cada concepto importante
3. **Ejemplos Pr√°cticos**: Ejemplos que ayuden a entender los conceptos
4. **Relaciones entre Conceptos**: C√≥mo se relacionan los diferentes temas
5. **Puntos Importantes a Recordar**: Lista de los puntos m√°s relevantes

Formato el resultado en Markdown con encabezados, listas y secciones bien organizadas.""")
        ])
        
        try:
            chain = prompt_template | self.llm
            explanation = chain.invoke({"content": combined_content})
            
            return {
                "explanations": explanation.content,
                "status": "success",
                "concepts_covered": len(all_content)
            }
        except Exception as e:
            return {
                "error": f"Error al generar explicaciones: {str(e)}",
                "status": "error"
            }
    
    def generate_notes(self, topics: Optional[List[str]] = None, model: Optional[str] = "gpt-4-turbo") -> str:
        """
        Genera apuntes completos en formato Markdown
        
        Args:
            topics: Lista de temas espec√≠ficos a cubrir (opcional)
            model: Modelo de OpenAI a usar (opcional, por defecto gpt-4-turbo)
            
        Returns:
            Apuntes en formato Markdown
        """
        # Verificar API key
        if not self.api_key:
            return "# Error\n\n‚ö†Ô∏è Se requiere configurar una API key de OpenAI para generar apuntes. Por favor, configura tu API key."
        
        # Inicializar LLM con el modelo especificado
        try:
            self.llm = ChatOpenAI(
                model=model,
                temperature=0.7,
                api_key=self.api_key,
                max_tokens=None
            )
        except Exception as e:
            # Si el modelo especificado falla, intentar con gpt-4-turbo como fallback
            try:
                print(f"‚ö†Ô∏è Modelo {model} no disponible, usando gpt-4-turbo como fallback")
                self.llm = ChatOpenAI(
                    model="gpt-4-turbo",
                    temperature=0.7,
                    api_key=self.api_key,
                    max_tokens=None
                )
            except:
                # √öltimo fallback a gpt-4o
                try:
                    print("‚ö†Ô∏è gpt-4-turbo no disponible, usando gpt-4o como fallback")
                    self.llm = ChatOpenAI(
                        model="gpt-4o",
                        temperature=0.7,
                        api_key=self.api_key,
                        max_tokens=None
                    )
                except Exception as e2:
                    return f"# Error\n\n‚ö†Ô∏è Error al inicializar el modelo: {str(e2)}"
        
        # Definir el prompt template que se usar√° en ambos casos
        # Usar raw string (r"""...""") para evitar problemas con secuencias de escape
        prompt_template = r"""Eres un profesor experto. Tu tarea es generar apuntes bas√°ndote √öNICA Y EXCLUSIVAMENTE en el contenido que se te proporciona a continuaci√≥n.

CONTENIDO DEL DOCUMENTO:
{content}

REGLAS ESTRICTAS:
1. SOLO puedes usar informaci√≥n que aparezca expl√≠citamente en el contenido proporcionado arriba
2. NO inventes, NO asumas, NO uses conocimiento previo que no est√© en el contenido
3. Si el contenido no menciona algo, NO lo incluyas en los apuntes
4. NO uses placeholders, templates o texto gen√©rico como "Concepto 1", "Aqu√≠ va...", etc.
5. Extrae y explica SOLO los conceptos, t√©rminos, definiciones y explicaciones que aparecen en el contenido proporcionado
6. Si el contenido est√° vac√≠o o no tiene informaci√≥n suficiente, di claramente: "El contenido proporcionado no contiene suficiente informaci√≥n para generar apuntes"

**‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è ADVERTENCIA CR√çTICA ANTES DE COMENZAR ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è**

**NO GENERES C√ìDIGO MERMAID DE NING√öN TIPO. ESTO ES ABSOLUTAMENTE PROHIBIDO.**

Si generas c√≥digo que comience con:
- \`\`\`mermaid
- \`\`\`flowchart
- \`\`\`graph
- \`\`\`gantt
- \`\`\`sequenceDiagram
- \`\`\`classDiagram
- \`\`\`mindmap

Tu respuesta ser√° INCORRECTA y NO se mostrar√°.

**SOLO puedes usar:**
- \`\`\`diagram-json (para diagramas conceptuales)
- Tablas Markdown (para calendarios/cronogramas)
- Texto estructurado

FORMATO DE SALIDA (Markdown ULTRA VISUAL y f√°cil de leer):
# Apuntes Generados

## Resumen Ejecutivo
[Resumen claro y conciso basado SOLO en el contenido proporcionado. M√°ximo 3-4 p√°rrafos. Si no hay suficiente informaci√≥n, ind√≠calo claramente]

## Conceptos Clave

Para CADA concepto importante del contenido, usa este formato visual:

### [Nombre del Concepto]

**Definici√≥n:** [Definici√≥n exacta y clara del contenido. Una o dos frases m√°ximo]

**Explicaci√≥n:** [Explicaci√≥n detallada pero comprensible del contenido. Usa lenguaje simple y claro]

**Ejemplos:** [Si el contenido incluye ejemplos, incl√∫yelos aqu√≠ de forma clara]

**Aplicaciones:** [Si el contenido menciona aplicaciones pr√°cticas, incl√∫yelas]

---

## Esquemas Conceptuales para Ex√°menes

**‚ö†Ô∏è CR√çTICO - LEE ESTO PRIMERO**: 
- **NO uses c√≥digo Mermaid de NING√öN TIPO** (NO flowchart, NO graph, NO gantt, NO sequenceDiagram, NO classDiagram, NO mindmap, NADA de Mermaid)
- **SOLO usa JSON estructurado** dentro de bloques \`\`\`diagram-json
- Si generas c√≥digo Mermaid (incluso gantt), la respuesta ser√° incorrecta y no se mostrar√°
- **Para calendarios, cronogramas o l√≠neas de tiempo**: NO uses diagramas gantt. En su lugar, usa:
  * Tablas en formato Markdown
  * Listas estructuradas con fechas
  * Texto organizado por secciones con fechas

**OBLIGATORIO**: Crea esquemas conceptuales SIMPLES usando JSON estructurado para CADA apartado o grupo de conceptos del contenido.

### REGLAS IMPORTANTES:

1. **Crea UN esquema por cada apartado/secci√≥n** - El esquema debe estar DENTRO del apartado correspondiente, justo despu√©s de la explicaci√≥n
2. **M√°ximo 5 nodos por esquema** - mant√©n los diagramas simples y claros
3. **Usa solo letras may√∫sculas** para IDs de nodos (A, B, C, D, E)
4. **Estructura OBLIGATORIA**: Cada apartado debe tener su esquema dentro de √©l:

```
## [Nombre del Apartado]

[Explicaci√≥n del apartado con conceptos clave]

### Esquema Conceptual: [Nombre del concepto del apartado]

\`\`\`diagram-json
{
  "nodes": [
    {"id": "A", "label": "Concepto Principal del Apartado", "color": "#6366f1"},
    {"id": "B", "label": "Caracter√≠stica 1", "color": "#10b981"},
    {"id": "C", "label": "Caracter√≠stica 2", "color": "#10b981"},
    {"id": "D", "label": "Caracter√≠stica 3", "color": "#10b981"}
  ],
  "edges": [
    {"from": "A", "to": "B"},
    {"from": "A", "to": "C"},
    {"from": "A", "to": "D"}
  ]
}
\`\`\`

[Continuaci√≥n del contenido del apartado...]
```

**IMPORTANTE**: 
- Los esquemas DEBEN estar dentro de cada apartado (##), no al final de todo
- Un esquema por cada grupo de conceptos relacionados
- NO uses c√≥digo Mermaid, SOLO JSON estructurado dentro de bloques \`\`\`diagram-json

**FORMATO PARA ESQUEMAS - USA SOLO JSON ESTRUCTURADO**:

En lugar de c√≥digo Mermaid, genera datos estructurados en JSON dentro de bloques de c√≥digo marcados como \`\`\`diagram-json

**FORMATO B√ÅSICO - COPIA EXACTAMENTE ESTO**:

\`\`\`diagram-json
{
  "nodes": [
    {"id": "A", "label": "Concepto Principal", "color": "#6366f1"},
    {"id": "B", "label": "Caracter√≠stica 1", "color": "#10b981"},
    {"id": "C", "label": "Caracter√≠stica 2", "color": "#10b981"},
    {"id": "D", "label": "Caracter√≠stica 3", "color": "#10b981"}
  ],
  "edges": [
    {"from": "A", "to": "B"},
    {"from": "A", "to": "C"},
    {"from": "A", "to": "D"}
  ]
}
\`\`\`

**REGLAS B√ÅSICAS**:

1. **FORMATO JSON**:
   - DEBE ser JSON v√°lido
   - Usa comillas dobles para todas las propiedades
   - NO uses comillas simples
   - Cada nodo debe tener: "id", "label", "color"
   - Cada conexi√≥n debe tener: "from", "to"

2. **NODOS**:
   - IDs: A, B, C, D, E (una letra may√∫scula)
   - Labels: Texto descriptivo del concepto (puede tener cualquier car√°cter)
   - Colors: Usa colores hexadecimales (#6366f1, #10b981, #8b5cf6, #06b6d4, #f59e0b)

3. **CONEXIONES**:
   - "from": ID del nodo origen
   - "to": ID del nodo destino
   - Sin etiquetas en las flechas por ahora

**EJEMPLO SIMPLE**:
Si el concepto es "Normalizaci√≥n", genera:
\`\`\`diagram-json
{
  "nodes": [
    {"id": "A", "label": "Normalizaci√≥n", "color": "#6366f1"},
    {"id": "B", "label": "Primera Forma Normal", "color": "#10b981"},
    {"id": "C", "label": "Segunda Forma Normal", "color": "#10b981"},
    {"id": "D", "label": "Tercera Forma Normal", "color": "#10b981"}
  ],
  "edges": [
    {"from": "A", "to": "B"},
    {"from": "A", "to": "C"},
    {"from": "A", "to": "D"}
  ]
}
\`\`\`

**IMPORTANTE**: 
- Mant√©n los esquemas SIMPLES. M√°ximo 5 nodos.
- El JSON DEBE ser v√°lido y estar correctamente formateado.
- NO uses c√≥digo Mermaid, solo JSON estructurado.

### Reglas SIMPLES para Esquemas:

- **Crea 1-2 esquemas** por cada tema principal (mant√©n simple)
- Cada esquema debe tener **m√°ximo 5 nodos**
- Usa **conexiones simples** (sin etiquetas en flechas por ahora)
- Aseg√∫rate de que el JSON sea v√°lido y est√© correctamente formateado

### EJEMPLO SIMPLE:

Para un contenido sobre "Fotos√≠ntesis", crea algo as√≠:

## Fotos√≠ntesis

La fotos√≠ntesis es el proceso por el cual las plantas convierten la luz solar en energ√≠a qu√≠mica.

### Esquema Conceptual: Proceso de Fotos√≠ntesis

\`\`\`diagram-json
{
  "nodes": [
    {"id": "A", "label": "Fotos√≠ntesis", "color": "#6366f1"},
    {"id": "B", "label": "Luz Solar", "color": "#10b981"},
    {"id": "C", "label": "Clorofila", "color": "#10b981"},
    {"id": "D", "label": "ATP y NADPH", "color": "#10b981"},
    {"id": "E", "label": "Glucosa", "color": "#10b981"}
  ],
  "edges": [
    {"from": "A", "to": "B"},
    {"from": "A", "to": "C"},
    {"from": "A", "to": "D"},
    {"from": "A", "to": "E"}
  ]
}
\`\`\`

---

### INSTRUCCIONES FINALES CR√çTICAS:

1. **NO GENERES APARTADOS VAC√çOS**: Si un apartado no tiene conceptos clave o informaci√≥n suficiente para crear un esquema, NO lo incluyas en la respuesta. Solo crea apartados que tengan contenido real y esquemas v√°lidos.

2. **JSON DE DIAGRAMA REAL**: NO uses placeholders. DEBES escribir el JSON completo y v√°lido dentro de bloques \`\`\`diagram-json. El JSON DEBE estar completo - NO lo cortes a mitad de un campo, NO dejes campos incompletos, aseg√∫rate de cerrar todas las llaves y corchetes.

3. **NO GENERES DIAGRAMAS GANTT**: Si el contenido incluye calendarios, cronogramas o l√≠neas de tiempo, NO uses diagramas gantt de Mermaid. En su lugar, presenta la informaci√≥n en formato de tabla o lista estructurada.

4. **ESTRUCTURA OBLIGATORIA**: Cada apartado DEBE tener:
   - T√≠tulo del apartado (##)
   - Explicaci√≥n del apartado con conceptos clave
   - Al menos UN esquema conceptual con JSON de diagrama completo dentro del apartado
   
5. **NO INCLUYAS MENSAJES DE ERROR**: Si no hay informaci√≥n suficiente, NO escribas mensajes como "no es posible crear esquemas" o "ausencia de informaci√≥n". Simplemente omite ese apartado completamente.

6. **VERIFICACI√ìN**: Antes de finalizar, cuenta cu√°ntos apartados/temas/conceptos clave identificaste. Aseg√∫rate de haber creado al menos un esquema por cada uno.

7. **PRIORIDAD**: Los esquemas son M√ÅS IMPORTANTES que el texto descriptivo. Si tienes que elegir entre m√°s texto o m√°s esquemas, elige m√°s esquemas.

8. **√öLTIMA VERIFICACI√ìN CR√çTICA**: Antes de enviar la respuesta, revisa que NO haya ning√∫n bloque de c√≥digo que comience con \`\`\`mermaid, \`\`\`gantt, \`\`\`flowchart, \`\`\`graph, \`\`\`sequenceDiagram, \`\`\`classDiagram, \`\`\`mindmap, etc. Si encuentras alguno, elim√≠nalo completamente y reempl√°zalo con JSON estructurado (para diagramas conceptuales) o texto/tablas (para calendarios y cronogramas).

**RECUERDA**: El objetivo es que un estudiante pueda repasar visualmente antes de un examen. Los esquemas son la herramienta principal para esto.

## Detalles Importantes

[Informaci√≥n espec√≠fica del contenido proporcionado. Organiza en listas con vi√±etas para facilitar la lectura. NO a√±adas informaci√≥n externa]

## Ejemplos Pr√°cticos

[Si el contenido incluye ejemplos, pres√©ntalos de forma clara y visual. Usa el formato:
- **Ejemplo 1:** [descripci√≥n]
- **Ejemplo 2:** [descripci√≥n]
]

## Tablas Comparativas

[Si es √∫til, crea tablas comparativas usando markdown para organizar informaci√≥n del contenido. Las tablas hacen la informaci√≥n m√°s f√°cil de comparar y entender]

| Concepto | Caracter√≠stica 1 | Caracter√≠stica 2 | Caracter√≠stica 3 |
|----------|------------------|------------------|------------------|
| [Del contenido] | [Del contenido] | [Del contenido] | [Del contenido] |

## Puntos Clave a Recordar

[Lista de 3-5 puntos m√°s importantes del contenido. Usa formato de lista con vi√±etas]

## Relaciones y Conexiones

[Si el contenido describe relaciones entre conceptos, expl√≠calas de forma clara y visual]

---

REGLAS DE FORMATO PARA M√ÅXIMA LEGIBILIDAD:
1. Usa **negritas** para t√©rminos importantes y conceptos clave
2. Usa listas con vi√±etas (‚Ä¢) para informaci√≥n que se puede escanear r√°pidamente
3. Usa tablas cuando compares conceptos o caracter√≠sticas
4. Separa secciones con l√≠neas horizontales (---) para mejor organizaci√≥n visual
5. **FORMATO VISUAL**: Usa negritas, listas, tablas y diagramas para hacer el contenido m√°s visual y f√°cil de escanear
6. Mant√©n p√°rrafos cortos (m√°ximo 3-4 l√≠neas)
7. Usa el formato "**Definici√≥n:**", "**Ejemplo:**", "**Importante:**" para crear bloques visuales destacados

RECUERDA: 
- Si el contenido no menciona algo espec√≠fico, NO lo inventes. Usa SOLO la informaci√≥n del contenido proporcionado.
- Prioriza la CLARIDAD y FACILIDAD DE LECTURA sobre la cantidad de informaci√≥n
- El objetivo es que cualquier persona pueda entender el contenido f√°cilmente
- Usa lenguaje simple y evita jerga t√©cnica innecesaria (a menos que est√© en el contenido original)
- **IMPORTANTE**: Prioriza la claridad y estructura visual sobre elementos decorativos."""

        if topics:
            # Buscar contenido relevante para cada tema
            relevant_content = []
            for topic in topics:
                content = self.memory.retrieve_relevant_content(topic, n_results=10)
                if content:
                    relevant_content.extend(content)
            combined_content = "\n\n---\n\n".join(relevant_content) if relevant_content else ""
        else:
            # Obtener contenido pero limitar usando conteo real de tokens
            all_content = self.memory.get_all_documents(limit=100)  # Aumentar l√≠mite para obtener m√°s contenido
            
            # Verificar que hay contenido
            if not all_content or len(all_content) == 0:
                print("‚ùå No hay documentos en la memoria")
                return "# Apuntes\n\n‚ö†Ô∏è No hay documentos procesados. Por favor, sube documentos primero."
            
            # Filtrar documentos vac√≠os o muy cortos
            all_content = [doc for doc in all_content if doc and doc.strip() and len(doc.strip()) > 10]
            
            if not all_content or len(all_content) == 0:
                print("‚ùå Todos los documentos est√°n vac√≠os o son muy cortos")
                return "# Apuntes\n\n‚ö†Ô∏è Los documentos procesados no contienen suficiente contenido. Por favor, sube documentos con m√°s texto."
            
            print(f"üìÑ Encontrados {len(all_content)} documentos con contenido v√°lido")
            print(f"üìÑ Primer documento (primeros 200 chars): {all_content[0][:200]}...")
            
            # Calcular tokens usando tiktoken para asegurar que no excedemos el l√≠mite
            try:
                encoding = tiktoken.encoding_for_model("gpt-4")
            except:
                encoding = tiktoken.get_encoding("cl100k_base")
            
            # Aumentar l√≠mite de tokens ya que estamos usando gpt-4-turbo o gpt-4o que tienen m√°s contexto
            MAX_CONTENT_TOKENS = 8000  # Aumentado para modelos con m√°s contexto
            combined_content = ""
            combined_tokens = 0
            
            # Calcular tokens del prompt base (sin contenido)
            prompt_base_tokens = len(encoding.encode(prompt_template.replace("{content}", "")))
            print(f"üìä Tokens del prompt base: {prompt_base_tokens}")
            print(f"üìä L√≠mite de tokens para contenido: {MAX_CONTENT_TOKENS}")
            
            for i, doc in enumerate(all_content):
                doc_text = f"\n\n---\n\n{doc}" if combined_content else doc
                doc_tokens = len(encoding.encode(doc_text))
                
                # Verificar si a√±adir este documento exceder√≠a el l√≠mite
                if combined_tokens + doc_tokens + prompt_base_tokens > MAX_CONTENT_TOKENS:
                    print(f"üìä L√≠mite alcanzado despu√©s de {i} documentos ({combined_tokens} tokens)")
                    # A√±adir nota de que hay m√°s contenido
                    combined_content += f"\n\n---\n\n[Nota: Hay m√°s contenido disponible. Se han incluido {i} documentos de {len(all_content)} disponibles. Para ver todo, puedes hacer preguntas espec√≠ficas sobre temas concretos.]"
                    break
                combined_content += doc_text
                combined_tokens += doc_tokens
                print(f"üìÑ Documento {i+1} a√±adido ({doc_tokens} tokens, total: {combined_tokens})")
            
            print(f"üìä Contenido final: {combined_tokens} tokens, {len(combined_content)} caracteres")
        
        if not combined_content or not combined_content.strip():
            return "# Apuntes\n\n‚ö†Ô∏è No hay contenido disponible. Por favor, sube documentos primero."
        
        # Verificar que el contenido no est√© vac√≠o despu√©s de limpiar
        if len(combined_content.strip()) < 50:
            return "# Apuntes\n\n‚ö†Ô∏è El contenido disponible es demasiado corto o est√° vac√≠o. Por favor, sube documentos con m√°s contenido."
        
        # A√±adir validaci√≥n: mostrar una muestra del contenido para debugging
        print(f"‚úÖ Generando apuntes con {len(combined_content)} caracteres de contenido")
        print(f"üìÑ Primeros 500 caracteres: {combined_content[:500]}...")
        print(f"üìÑ √öltimos 200 caracteres: {combined_content[-200:]}...")
        
        # Validar que el contenido tiene informaci√≥n real (no solo espacios o caracteres especiales)
        content_words = combined_content.split()
        if len(content_words) < 10:
            print(f"‚ùå Contenido tiene muy pocas palabras: {len(content_words)}")
            return "# Apuntes\n\n‚ö†Ô∏è El contenido disponible tiene muy pocas palabras. Por favor, sube documentos con m√°s texto."
        
        print(f"‚úÖ Contenido v√°lido: {len(content_words)} palabras")
        
        # Usar replace directo en lugar de format para evitar problemas con llaves en el contenido
        # Esto es m√°s seguro cuando el contenido puede contener llaves tambi√©n
        prompt = prompt_template.replace("{content}", combined_content)

        try:
            print("üîÑ Invocando LLM para generar apuntes...")
            response = self.llm.invoke(prompt)
            notes_content = response.content
            print(f"‚úÖ Respuesta recibida: {len(notes_content)} caracteres")
            print(f"üìÑ Primeros 300 caracteres: {notes_content[:300]}")
            
            # POST-PROCESAMIENTO: Eliminar cualquier bloque Mermaid que el modelo pueda haber generado
            import re
            # Detectar y eliminar bloques de c√≥digo Mermaid (multil√≠nea)
            # Patr√≥n mejorado que captura bloques completos con cualquier contenido entre los backticks
            mermaid_patterns = [
                r'```\s*mermaid\s*\n.*?```',
                r'```\s*flowchart\s*\n.*?```',
                r'```\s*graph\s*\n.*?```',
                r'```\s*gantt\s*\n.*?```',
                r'```\s*sequenceDiagram\s*\n.*?```',
                r'```\s*classDiagram\s*\n.*?```',
                r'```\s*mindmap\s*\n.*?```',
            ]
            
            for pattern in mermaid_patterns:
                notes_content = re.sub(pattern, '', notes_content, flags=re.DOTALL | re.IGNORECASE | re.MULTILINE)
            
            # Tambi√©n eliminar bloques que comiencen directamente con comandos Mermaid (sin backticks iniciales)
            mermaid_code_patterns = [
                r'graph\s+(TB|TD|LR|RL|BT).*?```',
                r'flowchart\s+(TB|TD|LR|RL|BT).*?```',
                r'gantt\s+.*?```',
            ]
            
            for pattern in mermaid_code_patterns:
                notes_content = re.sub(pattern, '', notes_content, flags=re.DOTALL | re.IGNORECASE | re.MULTILINE)
            
            # Limpiar l√≠neas vac√≠as m√∫ltiples que puedan quedar despu√©s de eliminar bloques
            notes_content = re.sub(r'\n{3,}', '\n\n', notes_content)
            
            # Validar que hay bloques diagram-json en la respuesta
            diagram_json_count = notes_content.count('```diagram-json') + notes_content.count('``` diagram-json')
            if diagram_json_count == 0:
                print("‚ö†Ô∏è Advertencia: No se encontraron bloques diagram-json en la respuesta")
                print(f"üìÑ Primeros 500 caracteres de la respuesta: {notes_content[:500]}")
            else:
                print(f"‚úÖ Post-procesamiento: Bloques Mermaid eliminados, {diagram_json_count} diagrama(s) JSON encontrado(s)")
            
            # Validar que la respuesta no est√© vac√≠a
            if not notes_content or not notes_content.strip():
                return "# Error\n\n‚ö†Ô∏è La respuesta del modelo est√° vac√≠a. Por favor, intenta de nuevo."
            
            # Validar que la respuesta contenga contenido v√°lido
            if len(notes_content.strip()) < 50:
                return f"# Error\n\n‚ö†Ô∏è La respuesta del modelo es demasiado corta. Respuesta recibida: {notes_content[:200]}"
            
            return notes_content
        except KeyError as e:
            error_str = str(e)
            print(f"‚ùå KeyError al generar apuntes: {error_str}")
            import traceback
            traceback.print_exc()
            return f"# Error\n\n‚ö†Ô∏è Error al procesar la respuesta: {error_str}. Por favor, intenta de nuevo o verifica que hay contenido disponible."
        except Exception as e:
            error_str = str(e)
            print(f"‚ùå Error al generar apuntes: {error_str}")
            import traceback
            traceback.print_exc()
            # Si el error es por l√≠mite de tokens, sugerir usar menos contenido
            if "context_length" in error_str.lower() or "tokens" in error_str.lower():
                return f"# Error\n\nEl contenido es demasiado extenso. Por favor, intenta generar apuntes sobre temas espec√≠ficos o divide el documento en partes m√°s peque√±as.\n\nError: {error_str}"
            return f"# Error\n\nNo se pudieron generar los apuntes: {error_str}"
    
    def explain_concept(self, concept: str) -> str:
        """
        Explica un concepto espec√≠fico
        
        Args:
            concept: Concepto a explicar
            
        Returns:
            Explicaci√≥n del concepto
        """
        # Verificar API key
        if not self.api_key:
            return f"# Concepto: {concept}\n\n‚ö†Ô∏è Se requiere configurar una API key de OpenAI para explicar conceptos."
        
        # Inicializar LLM si no est√° inicializado
        if not self.llm:
            try:
                # Usar gpt-4-turbo que tiene 128k tokens de contexto (m√°s reciente y estable)
                # Si no est√° disponible, usar gpt-4o que tambi√©n tiene contexto amplio
                try:
                    self.llm = ChatOpenAI(
                        model="gpt-4-turbo",
                        temperature=0.7,
                        api_key=self.api_key,
                        max_tokens=None
                    )
                except:
                    # Fallback a gpt-4o si gpt-4-turbo no est√° disponible
                    self.llm = ChatOpenAI(
                        model="gpt-4o",
                        temperature=0.7,
                        api_key=self.api_key,
                        max_tokens=None
                    )
            except Exception as e:
                return f"# Error\n\n‚ö†Ô∏è Error al inicializar el modelo: {str(e)}"
        
        relevant_content = self.memory.retrieve_relevant_content(concept, n_results=5)
        
        if not relevant_content:
            return f"# Concepto: {concept}\n\nNo se encontr√≥ informaci√≥n sobre '{concept}' en los documentos procesados. Por favor, aseg√∫rate de haber subido documentos que contengan este concepto."
        
        prompt = f"""Explica el concepto '{concept}' de manera clara y completa bas√°ndote en el siguiente contenido:

{chr(10).join(relevant_content)}

Proporciona:
1. Definici√≥n clara
2. Explicaci√≥n detallada
3. Ejemplos pr√°cticos
4. Relaci√≥n con otros conceptos
5. Puntos importantes a recordar

Formato en Markdown."""

        try:
            response = self.llm.invoke(prompt)
            return response.content
        except Exception as e:
            return f"Error al explicar el concepto: {str(e)}"
